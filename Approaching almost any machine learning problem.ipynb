{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised datasets may include datasets for customer segmentation\n",
    "Most of the time it's possible to convert a supervised dataset to unsupervised to see how they look when plotted\n",
    "\n",
    "Lets use MNIST datset which is a very popular dataset of handwritten digits.This dataset can easily be converted to an unsupervised setting for basic visualization.\n",
    "\n",
    "If I do  a t-Distributed Stochastic Neighbour Embedding(t-SNE) decompostion, we can see that we can separate the images to some extent just by doing two components on the image pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import manifold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.fetch_openml(\n",
    "                'mnist_784',\n",
    "                 version=1,\n",
    "                  return_X_y=True\n",
    ")\n",
    "pixel_values, targets = data\n",
    "targets = targets.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19ec5b1fb48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can visualize the samples in the dataset by reshaping them to their original shape and then plotting them using matplotlib\n",
    "single_image = pixel_values[1, :].reshape(28, 28)\n",
    "\n",
    "plt.imshow(single_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a t-SNE transformation of the data\n",
    "tsne = manifold.TSNE(n_components=2, random_state=42)\n",
    "\n",
    "transformed_data = tsne.fit_transform(pixel_values[:3000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.281551</td>\n",
       "      <td>-28.952768</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.105896</td>\n",
       "      <td>-68.069321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-42.503582</td>\n",
       "      <td>35.580391</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.893967</td>\n",
       "      <td>26.663395</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.770573</td>\n",
       "      <td>35.433247</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>9.038110</td>\n",
       "      <td>58.850792</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>-29.405334</td>\n",
       "      <td>-60.951775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>13.466378</td>\n",
       "      <td>47.369007</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>-2.435752</td>\n",
       "      <td>7.983772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>-4.248264</td>\n",
       "      <td>-13.266910</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x          y  targets\n",
       "0     -5.281551 -28.952768        5\n",
       "1    -26.105896 -68.069321        0\n",
       "2    -42.503582  35.580391        4\n",
       "3     38.893967  26.663395        1\n",
       "4    -14.770573  35.433247        9\n",
       "...         ...        ...      ...\n",
       "2995   9.038110  58.850792        7\n",
       "2996 -29.405334 -60.951775        0\n",
       "2997  13.466378  47.369007        9\n",
       "2998  -2.435752   7.983772        1\n",
       "2999  -4.248264 -13.266910        5\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting transformed data to a pandas dataframe \n",
    "tsne_df = pd.DataFrame(\n",
    "    np.column_stack((transformed_data, targets[:3000])),\n",
    "    columns=[\"x\",\"y\", \"targets\"]\n",
    ")\n",
    "\n",
    "tsne_df.loc[:, \"targets\"] = tsne_df.targets.astype(int)\n",
    "tsne_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're creating a pandas dataframe from a numpy array.\n",
    "There are three columns: x,y and targets. x and y are the two components from t-SNE decompositon and targets is the actual number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0972194ef1bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# plotting it using seaborn and matplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFacetGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtsne_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"targets\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"x\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_legend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'size'"
     ]
    }
   ],
   "source": [
    "# plotting it using seaborn and matplotlib\n",
    "\n",
    "grid = sns.FacetGrid(tsne_df, hue=\"targets\",size=8)\n",
    "grid.map(plt.scatter, \"x\", \"y\").add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do k-means clustering and see hoe it performs in an unsupervised setting.\n",
    "\n",
    "\n",
    "## Cross Validation\n",
    "This a technique for evaluating ML models by training several ML models on subsets of the available input data and evaluating them on the complementary subset of the data.\n",
    "\n",
    "We use it to detect ovefitting\n",
    "\n",
    "Lets look at the red-wine dataset which has 11 different attributes that decide the quality of red wine\n",
    "\n",
    "These attributes inlude:\n",
    " > firxed acidiy\n",
    " > volatile acidity\n",
    " > citric acid\n",
    " > residual sugar\n",
    " > chlorides\n",
    " > free sulfur dioxide\n",
    " > total sulfur dioxide\n",
    " > density\n",
    " > pH\n",
    " > sulphates\n",
    " > alcohol\n",
    " \n",
    "Based on these different attributes, we are required to predict the quality of red wine which is a value between 0 and 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv('C:/Users/PYTHON/OneDrive/Desktop/CSV.FILES/winequality-red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "wine_df = wine_df.reset_index(drop=True)\n",
    "print(wine_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treating the proble as a classification problem. Since the dataset consists of only six types of quality values, we will thus map all quality values from 0 to 5\n",
    "quality_mapping = {\n",
    "    3:0,\n",
    "    4:1,\n",
    "    5:2,\n",
    "    6:3,\n",
    "    7:4,\n",
    "    8:5,\n",
    "}\n",
    "# you can use the map function of pandas with\n",
    "# any dictionary to convert the values in a given\n",
    "# column to values in the directory\n",
    "wine_df.loc[:, \"quality\"] = wine_df.quality.map(quality_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets split the data to two parts\n",
    "# use sample with frac=1 to shuffle the dataframe\n",
    "# we reset the indices since they change after\n",
    "# shuffling the dataframe\n",
    "wine_df = wine_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# top 1000 rows are selected\n",
    "# for training\n",
    "df_train = wine_df.head(1000)\n",
    "\n",
    "# bottom 599 values are selected\n",
    "# for testing/validation\n",
    "df_test = wine_df.tail(599)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets train a decision tree model on the training set using scikit-learn\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "\n",
    "# initialize decision tree classifier class\n",
    "# with a max_depth of 3\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# choose the columns you want to train on\n",
    "# these are the features for the model\n",
    "cols = ['fixed acidity',\n",
    "       'volatile acidity',\n",
    "       'citric acid',\n",
    "       'residual sugar',\n",
    "       'chlorides',\n",
    "       'free sulfur dioxide',\n",
    "       'total sulfur dioxide',\n",
    "       'density',\n",
    "       'pH',\n",
    "       'sulphates',\n",
    "       'alcohol']\n",
    "# train the model on the provided feautres\n",
    "# and mapped quality from before\n",
    "clf.fit(df_train[cols], df_train.quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(df_test[cols], df_test.quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d03c496de4bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# compute the accuracy of the perdictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquality\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#print the accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# make predictions on the training set\n",
    "train_predictions = clf.predict(df_train[cols])\n",
    "\n",
    "# compute the accuracy of the perdictions\n",
    "accuracy = metrics.accuracy_score(df_train.quality,predictions)\n",
    "\n",
    "#print the accuracy\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = clf.predict(df_test[cols])\n",
    "\n",
    "accuracy = metrics.accuracy_score(df_test.quality,test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Accuracy: 0.6210350584307178\n"
     ]
    }
   ],
   "source": [
    "print(\"test_Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculating accuracies for different values of max_depth and making plots\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# global size of label text on the plots\n",
    "matplotlib.rc('xtick', labelsize=20)\n",
    "matplotlib.rc('ytick', labelsize=20)\n",
    "\n",
    "\n",
    "\n",
    "#initializing lists to store accuracies starting with 50% accuracy\n",
    "train_accuracies = [0.5]\n",
    "test_accuracies = [0.5]\n",
    "\n",
    "# iterate over a few depth values\n",
    "for depth in range(1, 25):\n",
    "    # init the model\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    \n",
    "    # columns/features for training\n",
    "    cols = [\n",
    "        'fixed acidity',\n",
    "        'volatile acidity',\n",
    "        'citric acid',\n",
    "        'residual sugar',\n",
    "        'chlorides',\n",
    "        'free sulfur dioxide',\n",
    "        'total sulfur dioxide',\n",
    "        'density',\n",
    "        'pH',\n",
    "        'sulphates',\n",
    "    ]\n",
    "    \n",
    "    # fit the model\n",
    "    clf.fit(df_train[cols], df_train.quality)\n",
    "    \n",
    "    # create training & test predictions\n",
    "    train_predictions = clf.predict(df_train[cols])\n",
    "    test_predictions = clf.predict(df_test[cols])\n",
    "    \n",
    "    # calculate training & test accuracies\n",
    "    train_accuracy = metrics.accuracy_score(df_train.quality, train_predictions)\n",
    "    test_accuracy = metrics.accuracy_score(df_test.quality, test_predictions)\n",
    "    \n",
    "    # append accuracies\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# create two plot\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.plot(train_accuracies, label=\"train accuracy\")\n",
    "plt.plot(test_accuracies, label=\"test accuracy\")\n",
    "plt.legend(loc=\"upper left\", prop={'size': 15})\n",
    "plt.xticks(range(0, 26, 5))\n",
    "plt.xlabel(\"max_depth\", size=20)\n",
    "plt.ylabel(\"accuracy\", size=20)\n",
    "plt.show\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good way to visualize how the model's acccuracy changes as you vary the value of `max_depth`. You are iterating over different values of `max_depth`, training a Decision Tree model on each value, making predictions on both the training and test sets, then calculating the accuracy of the predictons\n",
    "\n",
    "The plot shows the training and test accuracies as a function of `max_depth`. This can help one understand how the model's perfomance changes as you increase the depth of the tree\n",
    "\n",
    "It is generally a good idea to look at both the training and test accuracies as you vary the model hyperparameters, as this can give you an idea of whether the model is overfitting or underfitting to the training data. If the training accuracy is much higher than the test accuracy, it could indicate the model is overfitting and may not generalize well to new data. On the other hand, if the training accuracy is significantly lower that the test accuracy, it could mean that the model is underfitting and may not be able to capture the undelying patterns in the data.\n",
    "\n",
    "It is also a good idea to set the `random_state` parameter when creating the `DecisionTreeClassifier` object to ensure that the results are reproducible. This can be done by adding `random_state=123` initiallizing the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of cross validation\n",
    "\n",
    "> k-fold cross-validation\n",
    "> stratified k-fold cross-validation\n",
    "> hold-out based validation \n",
    "> leave-one-out cross validation\n",
    "> group k-fold cross-alidation\n",
    "\n",
    "Cross-validation is dividing training data into a few parts. We train the model on some of this parts and test on the remaining parts.\n",
    "\n",
    "We can split any data into k-equal parts using kFold from scikit-learn. Each sample is assigned a value from 9 to k-1 when using k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8dd581e10b3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# fetch targets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m#initiate the kfold class from model_selection module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'target'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "\n",
    "if not wine_df.empty==\"__main__\":\n",
    "    df = pd.read_csv('C:/Users/PYTHON/OneDrive/Desktop/CSV.FILES/winequality-red.csv')\n",
    "    \n",
    "    df[\"kfold\"] = -1\n",
    "    \n",
    "    # Randomizing the rows of the data\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # fetch targets\n",
    "    y = df.target.values\n",
    "    \n",
    "    #initiate the kfold class from model_selection module\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    # fill the new kfold column\n",
    "    for f, (t_, v_) in enumerate(kf.split(x=df, y=y)):\n",
    "        df.loc[v_, 'kfold'] = f\n",
    "        \n",
    "    # save the new csv with kfold column\n",
    "    df.to_csv(\"train_folds.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using the wine dataset, let us look at the distribution of labels\n",
    "b = sns.countplot(x='quality', data=wine_df)\n",
    "b.set_xlabel(\"quality\", fontsize=20)\n",
    "b.set_ylabel(\"count\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is the first and most essential step when it comes to building machine learning models. If you want to do feature engineering, split your data first. If you havea a good cross-validation scheme in which validation data is representative of training and real-world data, you will be able to build a good machine learning model which is highly generalizable.\n",
    "\n",
    "# Evaluation Metrics\n",
    "If we talk about classification problems, the most common metrics used are:\n",
    "> Accuracy\n",
    "> Precision(P)\n",
    "> Recall(R)\n",
    "> F1 score(F1)\n",
    "> Area under the ROC(Receiver Operating Characteristics) or simply AUC\n",
    "> Log loss\n",
    "> Precision at k(P@k)\n",
    "> Average precision at k(AP@k)\n",
    "> Mean average precision at k(MAP@k)\n",
    "\n",
    "When it come to regression, the most commonly used evaluation metrics are:\n",
    "\n",
    "> Mean absolute error(MAE)\n",
    "> Mean squared error(MSE)\n",
    "> Root mean squared error(RMSE)\n",
    "> Root mean squared logarithimic error(RMSLE)\n",
    "> Mean percentage error(MPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mean absolute percentage error(MAPE)\n",
    "* R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whe we have an equal number of positive and negative samples in a binary classification metric, we generally use accuracy, precision,recall and fl.\n",
    "\n",
    "### Accuracy\n",
    "It is one of the most straightforward metrics used in machine learning.\n",
    "It defines how accurate your model is. e.g if you build a model that classifies 90 images accurately, your accuracy is 90% or 0.90. If only 83 images are classified correctly, the accuracy of your model is 83% or 0.83.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate accuracy\n",
    "    :param y_true:list of values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: accuracy score\n",
    "    \"\"\"\n",
    "    # initialize a simple counter for correct predictions\n",
    "    correct_counter = 0\n",
    "    # loop over all elements of y_true\n",
    "    # and y_pred \"together\"\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == yp:\n",
    "            # if prediction is equal to truth, increase the counter\n",
    "            correct_counter += 1\n",
    "        \n",
    "    # return accuracy\n",
    "    #which is correct predictions over the number of samples\n",
    "    return correct_counter/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]\n",
    "metrics.accuracy_score(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True postive(TP)\n",
    "If your model predicts the image has pneomothorax, and the actual target for that image has pneomothorax image, it is considered a true positive.\n",
    "\n",
    "#### True negative(TN)\n",
    "If your model predicts that the image does not have pneumothorax and the actual target says that it is a non_pneumothorax image, it is considered as a true negative.\n",
    "\n",
    "In simple words, if your model correctly predicts positive class, it is true positive, and if your model accurately predicts negative class it is a true negative.\n",
    "\n",
    "#### False positive(FP)\n",
    "if your model predicts pneumthorax and the actual target for that image is non-pneumothorax, it is a false positive.\n",
    "\n",
    "#### False negative\n",
    "If your model predicts non-pneumothorax and the actual target is pneumothorax, it is a false negative.\n",
    "\n",
    "In simple words, if your model incorrrectly(or falsely) predicts postive class, it is a false positive.If your model incorrectly(or falsely) predicts negative class, it is a false negative.\n",
    "\n",
    "i.e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positive(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate True Positives\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of true positives\n",
    "    \"\"\"\n",
    "    \n",
    "    #initialize\n",
    "    tp = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            tp += 1\n",
    "    return tp\n",
    "\n",
    "def true_negative(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate True Negatives\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of true negatives\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize\n",
    "    tn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 0:\n",
    "            tn +=1\n",
    "    return tn\n",
    "\n",
    "def false_positive(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate False Positives\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of false postives\n",
    "    \"\"\"\n",
    "    # initialize\n",
    "    fp = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 1:\n",
    "            fp += 1\n",
    "    return fp\n",
    "\n",
    "def false_negative(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate False Negatives\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of false negatives\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize\n",
    "    fn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 0:\n",
    "            fn += 1\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive(l1,l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negative(l1,l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_negative(l1,l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Score = (TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_v2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Funtion to calculate accuracy using tp/tn/fp/fn\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: accuracy score\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    accuracy_score = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-05a406849b14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_v2(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "* It is one indicator of a machine learning model's perfomance- *the quality of a positive prediction made by the model*. Precision refers to the number of true postives divided by the total number of positive predictions(i.e the number of true positives plus the number of false positives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate precision\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: precision score\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    precision = tp / (tp + fp)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "    \n",
    "    * Recall = TP/(TP + FN)*\n",
    "  \n",
    "  Recall gives us information about a classifiers perfomance w.r.t the false negatives\n",
    "  Precision is about being being precise. It gives us info about perfomance w.r.t the false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate recall\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: recall score\n",
    "    \"\"\"\n",
    "    \n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    recall = tp / (tp + fn)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "recall(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the models predict a probability, and when we predict, we usually choose this threshold to be 0.5. This threshold is not always ideal, and depending on this threshold, your value of precision and recall can change drastically. If for every threshold we choose, we calculate the precision and recall values, we can create a plot between these sets of values. This plot or curve is known as the precision-recall curve.\n",
    "\n",
    "Let's assume two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
    "         1, 0, 0, 0, 0, 0, 0, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [0.02638412, 0.11114267, 0.31620708,\n",
    "          0.0490937,  0.0191491,  0.17554844,\n",
    "          0.15952202, 0.03819563, 0.11639273,\n",
    "          0.079377,   0.08584789, 0.039095342,\n",
    "          0.27259048, 0.03447096, 0.04644807,\n",
    "          0.03543574, 0.18521942, 0.05934905,\n",
    "          0.61977213, 0.33056815]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-227a21dc98df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_prediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_prediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mprecision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mrecall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    precision = tp / (tp + fp)\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    recall = tp / (tp + fn)\n",
    "    return recall\n",
    "\n",
    "# how we assumed these threholds is a long story\n",
    "thresholds =  [0.0490937 , 0.05934905, 0.079377,\n",
    "               0.08584789, 0.11114267, 0.11639273,\n",
    "               0.15952202, 0.17554844, 0.18521942,\n",
    "               0.27259048, 0.31620708, 0.33056815,\n",
    "               0.39095342, 0.61977213]\n",
    "\n",
    "# for every threshold, calculate predictions in binary\n",
    "# and append calculated precisions and recalls\n",
    "# to their respective lists\n",
    "for i in thresholds:\n",
    "    temp_prediction = [1 if x >= i else 0 for x in y_pred]\n",
    "    p = precision(y_true, temp_prediction)\n",
    "    r = recall(y_true, temp_prediction)\n",
    "    precision.append(p)\n",
    "    recall.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'function'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-fd8455233bf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Recall'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2767\u001b[0m     return gca().plot(\n\u001b[0;32m   2768\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2769\u001b[1;33m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2771\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1635\u001b[0m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1636\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1637\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1638\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request_autoscale_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36madd_line\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m   2286\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2288\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2289\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2290\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'_child{len(self._children)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m   2309\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2310\u001b[0m         \"\"\"\n\u001b[1;32m-> 2311\u001b[1;33m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2312\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2313\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\lines.py\u001b[0m in \u001b[0;36mget_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[1;34m\"\"\"Return the `~matplotlib.path.Path` associated with this line.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\lines.py\u001b[0m in \u001b[0;36mrecache\u001b[1;34m(self, always)\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[0mxconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_xunits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xorig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxconv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    653\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'function'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel('Recall', fontsize=15)\n",
    "plt.ylabel('Precision', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both precision and recall range from 0 to 1 and a value closer to 1 is better\n",
    "\n",
    "### F1 Score\n",
    "This is a metric that combines both precision and recall.\n",
    "It is defines as a simple weighted average(harmonic mean) of precision and recall.Lets denote precision using P and recall using R\n",
    "\n",
    "             F1 = 2TP/(2TP + FP + FN)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Funtction to calculate f1 score\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: f1 score\n",
    "    \"\"\"\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    \n",
    "    score = 2 * p * r / (p + r)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285715"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
    "         1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "\n",
    "y_pred = [0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
    "         1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "\n",
    "f1(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285715"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using scikit learn we get\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "metrics.f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score also ranges from 0 to 1, and a perfect prediction model has an F1 of 1. When dealing with datasets that have skewed targets, we should at F1 instead of accuracy.\n",
    "\n",
    "#### Crucial terms we should know\n",
    "\n",
    "* TPR or True Positive Rate, which is the same as recall.\n",
    "                \n",
    "                TPR = TP/(TP + FN)\n",
    "\n",
    "* TPR or recall is also known as sensitivity.\n",
    "* FPR or False Positive Rate, which is defined as:\n",
    "\n",
    "      FPR = FP / (TN + FP)\n",
    "* And 1-FPR is known as Specificity or True Negative Rate or TNR\n",
    "\n",
    "Let's calculate only two values i.e TPR and FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-01590cacf06c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mtemp_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# calculate tpr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtemp_tpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtpr_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;31m# calculate fpr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mtemp_fpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfpr_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "# empty lists to store tpr\n",
    "# and fpr values\n",
    "\n",
    "tpr_list = []\n",
    "fpr_list = []\n",
    "\n",
    "# actual targets\n",
    "y_true = [0, 0, 0, 0, 1, 0, 1,\n",
    "         0, 0, 1, 0, 1, 0, 0, 1]\n",
    "\n",
    "# predicted probabilities of a sample being 1\n",
    "y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05,\n",
    "          0.9, 0.5, 0.3, 0.66, 0.3, 0.2,\n",
    "          0.85, 0.15, 0.99]\n",
    "\n",
    "# handmade thresholds\n",
    "thresholds = [0, 0.1, 0.2, 0.3, 0.4, 0.5,\n",
    "             0.6, 0.7, 0.8, 0.85, 0.9, 0.99, 1.0]\n",
    "\n",
    "# loop over all thresholds\n",
    "for thresh in thresholds:\n",
    "    # calculate predictions for a given threshold\n",
    "    temp_pred = [1 if x >= thresh else 0 for x in y_pred]\n",
    "    # calculate tpr\n",
    "    temp_tpr = tpr_list(y_true, temp_pred)\n",
    "    # calculate fpr\n",
    "    temp_fpr = fpr_list(y_true, temp_pred)\n",
    "    # append tpr and fpr to lists\n",
    "    tpr_list.append(temp_tpr)\n",
    "    fpr_list.append(temp_fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting TPR on y-axis and FPR on the x-axis;\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.fill_between(fpr_list, tpr_list, alpha=0.4)\n",
    "plt.plot(fpr_list, tpr_list, lw=3)\n",
    "plt.xlim(0, 1.0)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.xlabel('FPR', fontsize=15)\n",
    "plt.ylabel('TPR', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The curve above is also known as the Receiver Operating Characteristic (ROC)\n",
    "\n",
    "### Area Under ROC Curve/Area Under Curve (AUC)\n",
    "\n",
    "This metric is used very often when you have a dataset which has skewed binary targets\n",
    "There are many ways to calculate the AUC we'll use scikit-learn for this purpose\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0, 0, 0, 0, 1, 0, 1,\n",
    "          0, 0, 1, 0, 1, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05,\n",
    "          0.9, 0.5, 0.3, 0.66, 0.3, 0.2,\n",
    "          0.85, 0.15, 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8300000000000001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC values range from 0 to 1\n",
    " * AUC = 1 implies you have a perfect model.\n",
    " * AUC = 0 implies that your model is very bad(or very good!). Try inverting the probabilities for the predictions e.g if your probability for the postive class is p, try substituing it with l-p. This kind of AUC may also mean that there is some problem with your validation or data processing.\n",
    " * AUC = 0.5 implies that your predictions are random. So, for any binary classification problem, if i predict all targets as 0.5, I will get an AUC of 0.5\n",
    " \n",
    "AUC values between 0 and 0.5 imply that your model is worse than random. Most of the time, it's because you inverted the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_positive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3aceb4f58edd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mtemp_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m>=\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# calculate tp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mtemp_tp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrue_positive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;31m# calculate fp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mtemp_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfalse_positive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true_positive' is not defined"
     ]
    }
   ],
   "source": [
    "# empty lists to store true postive\n",
    "# and false positive values\n",
    "tp_list = []\n",
    "fp_list = []\n",
    "\n",
    "# actual targets\n",
    "y_true = [0, 0, 0, 0, 1, 0, 1,\n",
    "          0, 0, 1, 0, 1, 0, 0, 1]\n",
    "\n",
    "# predicted probabilities of a sample being 1\n",
    "y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05,\n",
    "          0.9, 0.5, 0.3, 0.66, 0.3, 0.2,\n",
    "          0.85, 0.15, 0.99]\n",
    "\n",
    "# some handmade thresholds\n",
    "thresholds = [0, 0.1, 0.2, 0.3, 0.4, 0.5,\n",
    "              0.6, 0.7, 0.8, 0.85, 0.9, 0.99, 1.0]\n",
    "\n",
    "# loop over all thresholds\n",
    "for thresh in thresholds:\n",
    "    # calculate predictions for a given threshold\n",
    "    temp_pred = [1 if x>= thresh else 0 for x in y_pred]\n",
    "    # calculate tp\n",
    "    temp_tp = true_positive(y_true, temp_pred)\n",
    "    # calculate fp\n",
    "    temp_fp = false_positive(y_true, temp_pred)\n",
    "    # append tp and fp to lists\n",
    "    tp_list.append(temp_tp)\n",
    "    fp_list.append(temp_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC is widely used for skewed binary classification tasks in the indusry\n",
    "\n",
    "### LOG LOSS\n",
    "\n",
    "In the case of a binary classification problem, we use log loss. Where target is either 0 or 1 and the prediction is a probability of a sample belonging to class 1\n",
    "\n",
    "We define as:\n",
    "\n",
    "Log Loss = -1.0 * (target * log(prediction) + (1 - target) * log(1-prediction)\n",
    "\n",
    "Log loss penalizes quite high for an incorrect or a far-off prediction i.e log loss punishes you for being very sure and very wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def log_loss(y_true, y_proba):\n",
    "    \"\"\"\n",
    "    Function to calculate fpr\n",
    "    :param y_true: list of true values\n",
    "    :param y_proba: list of probalities for 1\n",
    "    :return: overall log loss\n",
    "    \"\"\"\n",
    "    \n",
    "    # define an epsilon value\n",
    "    # this can also be an input\n",
    "    # his value is used to clip probabilities\n",
    "    epsilon = 1e-15\n",
    "    # initialize empty list to store\n",
    "    # individual losses\n",
    "    loss = []\n",
    "    # loop over all true and predicted probability values\n",
    "    for yt, yp in zip(y_true, y_proba):\n",
    "        # adjust probability\n",
    "        # 0 gets converted to 1e-15\n",
    "        # 1 gets converted to 1-1e-15\n",
    "        # Why? Think abou it!\n",
    "        yp = np.clip(yp, epsilon, 1 - epsilon)\n",
    "        # calculate loss for one sample\n",
    "        temp_loss = -1.0*(\n",
    "            yt + np.log(yp)\n",
    "            + (1 - yt) * np.log(1 -yp)\n",
    "        )\n",
    "        # add to loss list\n",
    "        loss.append(temp_loss)\n",
    "        # return mean loss over all samples\n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0843794793256254"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 0, 0, 0, 1, 0, 1,\n",
    "          0, 0, 1, 0, 1, 0, 0, 1]\n",
    "y_proba = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05,\n",
    "           0.9, 0.5, 0.3, 0.66, 0.3, 0.2,\n",
    "           0.85, 0.15, 0.99]\n",
    "\n",
    "log_loss(y_true, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49882711861432294"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets compare this with scikit-learn\n",
    "from sklearn import metrics\n",
    "\n",
    "metrics.log_loss(y_true, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, even though we can choose a cut off at 0.5 and get perfect predictions, we will\n",
    "still have a very high log loss. So, when dealing with log loss, you need to be very\n",
    "careful; any non-confident prediction will have a very high log loss.\n",
    "\n",
    "Most of the metrics that we discussed until now can be converted to a multi_class version. We can calculate precision and recall for each class in a multi-class classification problem.\n",
    "\n",
    "Lets begin with precision first.We know that precision depends on true positives and false positives.\n",
    "\n",
    "   *### Macro averaged precision: calculate precision for all classes individually and average them\n",
    "   *### Micro averaged precision: calculate class wise true positive and false positive and the use tha to calculate overall precision\n",
    "   *### Weighted precision: same as macro but in this case, it is weighted average depending on the number of items in each class\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macro-averaged precision\n",
    "import numpy as np\n",
    "\n",
    "def macro_precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate macro averaged precision\n",
    "    :param y_true: list of true values\n",
    "    :param y_proba: list of predicted values\n",
    "    :return: macro precision score\n",
    "    \"\"\"\n",
    "    \n",
    "    # find the number of classes by taking\n",
    "    # length of unique values in true list\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # initializa precision to 0\n",
    "    precision = 0\n",
    "    \n",
    "    # loop over all classes\n",
    "    for class_ in range(num_classes):\n",
    "        \n",
    "        # all classes except curren class\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        # calculate true positives for current class\n",
    "        tp = true_positive(temp_true, temp_pred)\n",
    "        \n",
    "        # calculate false positive for current class\n",
    "        temp_precision = tp / (tp + fp)\n",
    "        \n",
    "        # keep adding precision for all classes\n",
    "        precision += temp_precision\n",
    "        \n",
    "    # calculate and return average precision over all classes\n",
    "    precison /= num_classes\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# micro precision\n",
    "\n",
    "import numpy as np\n",
    "def micro_precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate micro averaged precision\n",
    "    :param y_true: list of true values\n",
    "    :param y_proba: list of predicted values\n",
    "    return: micro precision score\n",
    "    \"\"\"\n",
    "    \n",
    "    # find the number of classes by taking\n",
    "    # length of unique alues in true list\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # initialize tp and fp to 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    # loop over all classes\n",
    "    for class_ in range(num_classes):\n",
    "        # all classes except current are considered negative\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        # calculate true positve for current class\n",
    "        # and update overall tp\n",
    "        tp += true_positive(temp_true, temp_pred)\n",
    "        \n",
    "    # calculate and return overall precision\n",
    "    precision = tp / (tp + fp)\n",
    "    return precison\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of weighted precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def weighted_precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate weighted averaged precision\n",
    "    :param y_true: list of true values\n",
    "    :param y_proba: list of predicted values\n",
    "    :return: weighted precision score\n",
    "    \"\"\"\n",
    "    # find the number of classes by taking\n",
    "    # length of unique values in true list\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # create class:sample count dictionary\n",
    "    # it looks something like this:\n",
    "    # {0:20, 1:15, 2:21}\n",
    "    class_counts = Counter(y_true)\n",
    "    \n",
    "    # initialize precision to 0\n",
    "    precision = 0\n",
    "    \n",
    "    # loop over all classes\n",
    "    for class_ in range(num_classes):\n",
    "        # all classes except current are considered negative\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        # calculate tp and fp for class\n",
    "        tp = true_positve(temp_true, temp_pred)\n",
    "        fp = false_positive(temp_true, temp_pred)\n",
    "        \n",
    "        # calculate precision of class\n",
    "        temp_precision = tp / (tp + fp)\n",
    "        \n",
    "        # multiply precision with count of samples in class\n",
    "        weighted_precision = class_counts[class_] * temp_precison\n",
    "        \n",
    "        # add to overall precision\n",
    "        precision += weighted_precision\n",
    "    # calculate overall precision by dividing by\n",
    "    # total number of samples\n",
    "    overall_precision = precision / len(y_true)\n",
    "    return overall_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing our implementations with scikit-learn to know if we implemented it right\n",
    "from sklearn import metrics\n",
    "\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_positive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0657e69471f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmacro_precision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-f4aac9143873>\u001b[0m in \u001b[0;36mmacro_precision\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# calculate true positives for current class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrue_positive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# calculate false positive for current class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true_positive' is not defined"
     ]
    }
   ],
   "source": [
    "macro_precision(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3611111111111111"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_true, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_true, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_positive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-896db0cde193>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmicro_precision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-f35811ef1144>\u001b[0m in \u001b[0;36mmicro_precision\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# calculate true positve for current class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# and update overall tp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mtp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrue_positive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# calculate and return overall precision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true_positive' is not defined"
     ]
    }
   ],
   "source": [
    "micro_precision(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_positve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-56b3ccf6d979>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mweighted_precision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-b94e81066c35>\u001b[0m in \u001b[0;36mweighted_precision\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# calculate tp and fp for class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrue_positve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfalse_positive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true_positve' is not defined"
     ]
    }
   ],
   "source": [
    "weighted_precision(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39814814814814814"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_true, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform the recall metric for multi-class as well as F1. You can similarly convert AUC and logg loss to multi_class formats too. This format of converdion is known as one-vs-all\n",
    "\n",
    "In binary or multi_class classification, it is also quite popular to look at confusion matrix which is a table of TP,FP,TN, & FN. Using the confusion matrix, you can quickly see how many samples were misclassified and how many were classified correctly.\n",
    "\n",
    "We need to calculate precision, recall, F1 score and AUC. FP is referred to as Type-1 error and FN as Type-2 error\n",
    "\n",
    "A perfect confusion matrix should only be filled diagonally from left to right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 50.5, 'Predicted Labels')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of a confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "# some targets\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "\n",
    "#some predictions\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]\n",
    "\n",
    "# get confusion matrix from sklearn\n",
    "cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# plot using matplotlib and seaborn\n",
    "plt.figure(figsize=(10, 10))\n",
    "cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0, as_cmap=True)\n",
    "sns.set(font_scale=2.5)\n",
    "sns.heatmap(cm, annot=True, cmap=cmap, cbar=False)\n",
    "plt.ylabel('Actual Labels', fontsize=20)\n",
    "plt.xlabel('Predicted Labels', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've tackled metrics for binary and multi-class classification\n",
    "The comes another type of classification called Multi_label classification\n",
    "\n",
    "Here each sample can have one or more classes associated with it. One simple example of this type of problem would be a task in which you are asked to predict different objects in a given image.The metrics for this classification problem include:\n",
    "*> Precision at k(P@k)\n",
    "*> Average precision at k(AP@k)\n",
    "*> Mean average precision at k(MAP@k)\n",
    "*> Log loss\n",
    "\n",
    "#### Precision at k or P@k\n",
    "\n",
    "If you have a list of original classes for a given sample and a lsit of predicted classes for the same, precision is defined as the number of hits in the predicted list considering only top-k predictions, divided by k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    This function calculates precision at k for a single sample\n",
    "    :param y_true: list of values, actual classes\n",
    "    :param y_pred: list of vslues, predicted classes\n",
    "    :return: precison at a given value k\n",
    "    \"\"\"\n",
    "    \n",
    "    # if k is 0, return 0. We should never have this as k is always >= 1\n",
    "    if k == 0:\n",
    "        return 0\n",
    "    # we are interested only in top-k predictions\n",
    "    y_pred = y_pred[:k]\n",
    "    #convert predictions to set\n",
    "    pred_set = set(y_pred)\n",
    "    # convert actual values to set\n",
    "    true_set = set(y_true)\n",
    "    # find common values\n",
    "    common_values = pred_set.intersection(true_set)\n",
    "    # return length of common values over k\n",
    "    return len(common_values)/ len(y_pred[:k])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have precsion AP@k and is calculate using P@k. For example, if we have to calculate AP@3, we calculate AP@1, AP@2 and AP@3 and then divide the sum by 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    This function calculates average precison at k\n",
    "    for a single sample\n",
    "    :param y_true: list of values, actual classes\n",
    "    :param y_pred: list of values, predicted classes\n",
    "    :return: average precision at a given value k\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize p@k list of values\n",
    "    pk_values = []\n",
    "    # loop over all k. from 1 to k + 1\n",
    "    for i in range(1, k + 1):\n",
    "        # calculate p@i and append to list\n",
    "        pk_values.append(pk(y_true, y_pred, i))\n",
    "    \n",
    "    # if we have no values in the list, return 0    \n",
    "    if len(pk_values) == 0:\n",
    "        return 0\n",
    "    # else, we return the sum of list over length of list\n",
    "    return sum(pk_values) / len(pk_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAP@k is just an average of AP@k and can be calculated easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapk(y_true, y_pred, k):\n",
    "    # initialize empty list for apk values\n",
    "    apk_values = []\n",
    "    # loop over all samples\n",
    "    for i in range(len(y_true)):\n",
    "        # store apk values for every sample\n",
    "        apk_values.append(\n",
    "           apk(y_true[i], y_pred[i], k=k)\n",
    "        )\n",
    "        \n",
    "    # return mean of apk values list\n",
    "    return sum(apk_values) / len(apk_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P@k, AP@k, and MAP@k all range from 0 to 1 with 1 being the best.\n",
    "\n",
    "For log loss for multi-label classification, you convert the targets to binary format and then use a log loss for each column. In the end, you can take the average of log loss in each column. This is also known as mean column-wise log loss.\n",
    "\n",
    "# Regression metrics\n",
    "\n",
    "Error = True Value - Predicted Value\n",
    "\n",
    "Absolute error = Abs(True Value - Predicted Value)\n",
    "\n",
    "The mean absolute error(MAE). It's just mean of all absolute errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates mae\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: mean absolute error\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    # loop over all samples in the true and predicted list\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # calculate absolute error\n",
    "        # and add to error\n",
    "        error += np.abs(yt - yp)\n",
    "        \n",
    "    # return mean error\n",
    "    return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared error(MSE).\n",
    "\n",
    "Squared Error = (True Value - Predicted Value)^2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    # loop over all samples in the true and prediced list\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # calculate squared error\n",
    "        # and add to error\n",
    "        error += (yt - yp) ** 2\n",
    "    # return mean error\n",
    "    return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLE (Squared logarithimic error)\n",
    "\n",
    "Involves taking mean of this error across all samples. It is also known as MSLE(Mean Squared Logarithimic error)\n",
    "\n",
    "Root mean squared logarithimic error is just a square root of this. It is also known as RMSLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_squared_log_error(y_true, y_pred):\n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    # loop over all samples in true and predicted list\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # calculate squared log error\n",
    "        # and add to error\n",
    "        error += (np.log(1 + yt) - np.log(1 + yp)) ** 2\n",
    "        # return mean error\n",
    "        return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have the percentage error\n",
    "\n",
    "Percentage Error = ((True Value - Predicted Value) / True Value) * 100\n",
    "\n",
    "The same can be converted to mean percentage error for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_percentage_error(y_true, y_pred):\n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    \n",
    "    # loop over all samples in true and predicted list\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # calculate percentage error\n",
    "        # and add to error\n",
    "        error += (yt - yp) / yt\n",
    "        \n",
    "    # return mean percentage error\n",
    "    return error / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean absolute percentage error\n",
    "import numpy as np\n",
    "\n",
    "def mean_abs_percentage_error(y_true, y_pred):\n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    # loop over all samples in true and predicted list\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # calculate percentage error\n",
    "        # and add to error\n",
    "        error += np.abs(yt - yp) / yt\n",
    "        \n",
    "    # return mean percentage error\n",
    "    return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R^2( R-squared)\n",
    "\n",
    "Also known as the coefficient of determination\n",
    "\n",
    "It says how good your model fits the data. if it is closer to 1.0 says that the model fits the data well, whereas closer 0 means that model isn't that good. When the model is absurd, the R-squared is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(y_true, y_pred):\n",
    "    # calculate the mean value of true values\n",
    "    mean_true_value = np.mean(y_true)\n",
    "    \n",
    "    # initialize numerator with 0\n",
    "    numerator = 0\n",
    "    # initialize denominator with 0\n",
    "    denominator = 0\n",
    "    \n",
    "    # loop over all true and predicted values\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # update numerator\n",
    "        numerator += (yt - yp) ** 2\n",
    "        # update denominator\n",
    "        denominator += (yt - mean_true_value) ** 2\n",
    "    # calculate the ratio\n",
    "    ratio = numerator / demoninator\n",
    "    return 1 - ratio\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1, 2, 3, 1, 2, 3, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [2, 1, 3, 1, 2, 3, 3, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333337"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matthew's Correlation Coefficient(MCC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates Matthew's Correlation Coefficient\n",
    "    for binary classification.\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: mcc score\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    fn = false_negatively(y_true, y_pred)\n",
    "    \n",
    "    numerator = (tp * tn) - (fp * fn)\n",
    "    \n",
    "    denominator = (\n",
    "        (tp + fp) *\n",
    "        (fn + tn) *\n",
    "        (fp + tn) *\n",
    "        (tp + fn) \n",
    "    )\n",
    "    \n",
    "    denominator = denominator ** 0.5\n",
    "    \n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranging machine learning projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import manifold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.fetch_openml(\n",
    "                'mnist_784',\n",
    "                 version=1,\n",
    "                  return_X_y=True\n",
    ")\n",
    "pixel_values, targets = data\n",
    "targets = targets.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approaching categorical variables\n",
    "\n",
    "They can be classsified into two major types\n",
    "> Nominal\n",
    "> Ordinal\n",
    "\n",
    "### Categorical Features Encoding\n",
    "\n",
    "I will be using cat-in-the-dat data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>02e7c8990</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>c</td>\n",
       "      <td>U</td>\n",
       "      <td>Pw</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Star</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>f37df64af</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Warm</td>\n",
       "      <td>e</td>\n",
       "      <td>X</td>\n",
       "      <td>pE</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>n</td>\n",
       "      <td>P</td>\n",
       "      <td>eN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>f9d456e57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>c5361037c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>C</td>\n",
       "      <td>OZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2       nom_3  \\\n",
       "0   0    0.0    0.0    0.0     F     N   Red  Trapezoid  Hamster      Russia   \n",
       "1   1    1.0    1.0    0.0     F     Y   Red       Star  Axolotl         NaN   \n",
       "2   2    0.0    1.0    0.0     F     N   Red        NaN  Hamster      Canada   \n",
       "3   3    NaN    0.0    0.0     F     N   Red     Circle  Hamster     Finland   \n",
       "4   4    0.0    NaN    0.0     T     N   Red   Triangle  Hamster  Costa Rica   \n",
       "\n",
       "   ...      nom_9 ord_0        ord_1     ord_2 ord_3 ord_4  ord_5  day month  \\\n",
       "0  ...  02e7c8990   3.0  Contributor       Hot     c     U     Pw  6.0   3.0   \n",
       "1  ...  f37df64af   3.0  Grandmaster      Warm     e     X     pE  7.0   7.0   \n",
       "2  ...        NaN   3.0          NaN  Freezing     n     P     eN  5.0   9.0   \n",
       "3  ...  f9d456e57   1.0       Novice  Lava Hot     a     C    NaN  3.0   3.0   \n",
       "4  ...  c5361037c   3.0  Grandmaster      Cold     h     C     OZ  5.0  12.0   \n",
       "\n",
       "  target  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "\n",
    "df = pd.read_csv('C:/Users/PYTHON/OneDrive/Desktop/CSV.FILES/catinthedat/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>600000.000000</td>\n",
       "      <td>582106.000000</td>\n",
       "      <td>581997.000000</td>\n",
       "      <td>582070.000000</td>\n",
       "      <td>581712.000000</td>\n",
       "      <td>582048.000000</td>\n",
       "      <td>582012.000000</td>\n",
       "      <td>600000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>299999.500000</td>\n",
       "      <td>0.092301</td>\n",
       "      <td>0.185532</td>\n",
       "      <td>0.278704</td>\n",
       "      <td>1.948224</td>\n",
       "      <td>4.112767</td>\n",
       "      <td>6.371317</td>\n",
       "      <td>0.187205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>173205.225094</td>\n",
       "      <td>0.289451</td>\n",
       "      <td>0.388729</td>\n",
       "      <td>0.448362</td>\n",
       "      <td>0.853904</td>\n",
       "      <td>2.034430</td>\n",
       "      <td>3.458959</td>\n",
       "      <td>0.390076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>149999.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>299999.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>449999.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>599999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id          bin_0          bin_1          bin_2  \\\n",
       "count  600000.000000  582106.000000  581997.000000  582070.000000   \n",
       "mean   299999.500000       0.092301       0.185532       0.278704   \n",
       "std    173205.225094       0.289451       0.388729       0.448362   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%    149999.750000       0.000000       0.000000       0.000000   \n",
       "50%    299999.500000       0.000000       0.000000       0.000000   \n",
       "75%    449999.250000       0.000000       0.000000       1.000000   \n",
       "max    599999.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "               ord_0            day          month         target  \n",
       "count  581712.000000  582048.000000  582012.000000  600000.000000  \n",
       "mean        1.948224       4.112767       6.371317       0.187205  \n",
       "std         0.853904       2.034430       3.458959       0.390076  \n",
       "min         1.000000       1.000000       1.000000       0.000000  \n",
       "25%         1.000000       2.000000       3.000000       0.000000  \n",
       "50%         2.000000       5.000000       6.000000       0.000000  \n",
       "75%         3.000000       6.000000       8.000000       0.000000  \n",
       "max         3.000000       7.000000      12.000000       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hot', 'Warm', 'Freezing', 'Lava Hot', 'Cold', 'Boiling Hot', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this shows the data is skewed so we will use AUC as a metric\n",
    "df.ord_2.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         4.0\n",
      "1         1.0\n",
      "2         0.0\n",
      "3         5.0\n",
      "4         2.0\n",
      "         ... \n",
      "599995    0.0\n",
      "599996    3.0\n",
      "599997    0.0\n",
      "599998    1.0\n",
      "599999    3.0\n",
      "Name: ord_2, Length: 600000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#We will use the ord_2 column which has six different values. We need to convert it into numeric\n",
    "# I will create a dictionary that maps these values to numbers i.e 1,2,3-N where N is the total number of categories in a given feature\n",
    "mapping = {\n",
    "    \"Freezing\" : 0,\n",
    "    \"Warm\" : 1,\n",
    "    \"Cold\" : 2,\n",
    "    \"Boiling Hot\" : 3,\n",
    "    \"Hot\" : 4,\n",
    "    \"Lava Hot\" : 5\n",
    "}\n",
    "\n",
    "df.loc[:, \"ord_2\"] = df.ord_2.map(mapping)\n",
    "print(df.ord_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can do the above proces using sklearn\n",
    "from sklearn import preprocessing\n",
    "def mapping(df):\n",
    "    # fill NaN with NONE\n",
    "    df.loc[:, 'ord_2'] = df['ord_2'].fillna(\"NONE\")\n",
    "    \n",
    "    label_enc = preprocessing.LabelEncoder()\n",
    "    \n",
    "    # P.S: do not use this directly. fit first, then transform\n",
    "    \n",
    "    df.loc[:, 'ord_2'] = label_enc.fit_transform(df['ord_2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.,  1.,  0.,  5.,  2.,  3., nan])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.,  1.,  0.,  5.,  2.,  3., nan])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this directlyin many tree-based models:\n",
    " * Decision Trees\n",
    " * Random Forest\n",
    " * Extra Trees\n",
    " * Or any kind of boosted trees model like:\n",
    "               XGBoost, GBM, LightGBM\n",
    "\n",
    "This type of encoding cannot be used in linear models, support vector machines or neural networks as they expect data to be normalized(or standardized)\n",
    "\n",
    "For this type of models, We can binarize the data. This is just converting the categories t numbers and then converting them to their binary representation.\n",
    "\n",
    "e.g freezing : 0 0 0 1\n",
    "    warm : 0 0 1 0\n",
    "    cold : 0 0 1 1\n",
    "Thus we're splitting one feature into three(in this case) feature(or columns). If we have more categories, we might end up splitting into a lot more columns.\n",
    "\n",
    "It becomes easy to store lots of binarized variables like this if we store them in a sparse format\n",
    "`A Sparse format` is nothing but a representation or way of storing data in memory in which you do not store all the values that matter. In this case of binary varibales described above, all that matters is where we have ones(1s)\n",
    "\n",
    "Our features are stored in the form of a matrix\n",
    "\n",
    "lets use a simple python snippet\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# create a feature matrix\n",
    "\n",
    "example = np.array(\n",
    "    [\n",
    "        [0, 0, 1],\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# print size in bytes\n",
    "print(example.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    [0,0,1],\n",
    "    [1,0,0],\n",
    "    [1,0,1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(data.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = example.size*example.itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "sparse_data = sparse.csr_matrix(data)\n",
    "print(sparse_data.data.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(sparse_data.data.nbytes + sparse_data.indptr.nbytes + sparse_data.indices.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.45 GiB for an array with shape (1000000, 1000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-b8ffbfe1f06b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mone_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0moh_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"size of dense array : {oh_data.nbytes}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \"\"\"\n\u001b[0;32m    487\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    555\u001b[0m         )\n\u001b[0;32m    556\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1025\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1026\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.45 GiB for an array with shape (1000000, 1000) and data type float64"
     ]
    }
   ],
   "source": [
    "# There is another transformatoin which makes much less memory than sparse mastrix as well\n",
    "# and that is one-hot encoding\n",
    "# just look at the image below\n",
    "from sklearn import preprocessing\n",
    "\n",
    "data = np.array([\n",
    "    [0,0,0,0,1,0],\n",
    "    [0,1,0,0,0,0],\n",
    "    [1,0,0,0,0,0]\n",
    "])\n",
    "\n",
    "sparse_d = sparse.csr_matrix(data)\n",
    "print(sparse_d.data.nbytes + sparse_d.indptr.nbytes + sparse_d.indices.nbytes)\n",
    "# this iis just 52\n",
    "\n",
    "# let's implement it on big data\n",
    "\n",
    "data = np.random.randint(1000, size=1000000)\n",
    "\n",
    "one_hot = preprocessing.OneHotEncoder(sparse = False)\n",
    "oh_data = one_hot.fit_transform(data.reshape(-1,1))\n",
    "print(f\"size of dense array : {oh_data.nbytes}\")\n",
    "\n",
    "one_hot = preprocessing.OneHotEncoder(sparse = True)\n",
    "oh_data = one_hot.fit_transform(data.reshape(-1,1))\n",
    "print(f\"size of full sparse array : {oh_data.data.nbytes + oh_data.indptr.nbytes + oh_data.indices.nbytes}\")\n",
    "\n",
    "      \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse representation of binarized features takes much less memory that its dense representation but we can use `One Hot Encoding'\n",
    "\n",
    "One hot encoding is a vector representation of our values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 72\n",
      "Size of the sparse array: 12\n",
      "Full size of sparse array: 40\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "# create binary matrix\n",
    "example = np.array(\n",
    "    [\n",
    "        [0, 0, 0, 0, 1, 0],\n",
    "        [0, 1, 0, 0, 0, 0],\n",
    "        [1, 0, 0, 0, 0, 0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# print size in bytes\n",
    "print(f\"Size of dense array: {example.nbytes}\")\n",
    "\n",
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of the sparse array: {sparse_example.data.nbytes}\")\n",
    "\n",
    "full_size = (\n",
    "    sparse_example.data.nbytes +\n",
    "    sparse_example.indptr.nbytes +\n",
    "    sparse_example.indices.nbytes\n",
    ")\n",
    "\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use OneHotEncoder from scikit-learn to transform our feature array with 1001 categories into dense and saprse matrices\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# create random 1-d array with 1001 diffrent categories (int)\n",
    "example = np.random.randint(1000, size=1000000)\n",
    "\n",
    "# initialize OneHotEncoder from scikit-learn\n",
    "# keep sparse = False to get dense array\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "# fit and transform data with dense one hot encoder\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1, 1))\n",
    "\n",
    "# print size in bytes for dense array\n",
    "print(f\"Size of dense array: {ohe_example.nbytes}\")\n",
    "\n",
    "# initialize OneHotEncoder\n",
    "# keep sparse = True to get sparse array\n",
    "ohe = preprocessing.OneHotEncounter(sparse=True)\n",
    "\n",
    "# fit and transform data with sparse one-hot encoder\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1, 1))\n",
    "\n",
    "full_size = (\n",
    "    ohe_example.data.nbytes +\n",
    "    ohe_example.indptr.nbytes + ohe_example.indices.nbytes\n",
    ")\n",
    "\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
